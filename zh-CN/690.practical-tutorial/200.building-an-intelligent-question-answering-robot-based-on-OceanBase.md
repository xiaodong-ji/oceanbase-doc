# 基于 OceanBase 构建智能问答机器人

## 背景信息

在当今信息爆炸的时代，用户常需要从海量数据中迅速检索所需信息。例如在线文献数据库、电商平台产品目录、以及不断增长的多媒体内容库，都需要高效的检索系统来快速定位到用户感兴趣的内容。随着数据量不断激增，传统的基于关键字的检索方法已经无法满足用户对于检索精度和速度的需求，向量检索技术应运而生。它通过将文本、图片、音频等不同类型的数据编码为数学上的向量，并在向量空间中进行检索。这种方法允许系统捕捉数据的深层次语义信息，从而提供更为准确和高效的检索结果。

本文通过 OceanBase 的向量检索能力构建文档智能助手。

## 文档智能助手架构

文档智能助手将文档以向量的形式批量存储在 OceanBase 数据库内。用户通过 UI 界面提问，程序使用 BGE-M3 模型将提问内容嵌入成为向量并在数据库中检索相似向量，得到相似向量对应的文档内容后，应用将它们会同用户提问一起发送给 LLM，LLM 会根据提供的文档生成更加准确的回答。

![5](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/observer-enterprise/V4.3.3/practical-tutorial/building-an-intelligent-question-answering-robot-based-on-OceanBase.png)

## 前提条件

* 您已部署 OceanBase V4.3.3 及以上版本的集群并且创建了 MySQL 模式租户。更多有关部署 OceanBase 集群的信息，请参见 [部署概述](../400.deploy/100.deploy-overview.md)

* 您所创建的 MySQL 模式租户需要拥有插入及查询的权限。更多有关权限设置的信息，请参见 [直接授予权限](../600.manage/500.security-and-permissions/300.access-control/200.user-and-permission/200.permission-of-mysql-mode/200.authority-of-mysql-mode.md)。

* 您已创建数据库。更多有关创建数据库的信息，请参见 [创建数据库](../300.develop/100.application-development-of-mysql-mode/300.database-object-planning-of-mysql-mode/100.create-database-of-mysql-mode-in-develop.md)。


* 数据库已开启向量检索功能。更多关于向量检索功能的信息，请参见 [使用 SQL 快速进行向量检索](../640.ob-vector-search/120.ob-vector-search-quick-start/100.ob-vector-search-sql-quick-start.md)。

    ```shell
    obclient> ALTER SYSTEM SET ob_vector_memory_limit_percentage = 30;
    ```

* 安装 Python 3.9 及以上版本。

* 安装 Poetry：

    ```shell
    python3 -m ensurepip
    python3 -m pip install poetry
    ```

## 操作步骤

1. 注册 Zhipu LLM 平台账号。

    注册 [Zhipu LLM](https://open.bigmodel.cn/login?redirect=%2Fusercenter%2Fapikeys)，获取 API 密钥。

    <main id="notice" type='notice'>
      <h4>注意</h4>
      <ul><li>Zhipu LLM 提供了一定的免费使用额度。使用过程中请关注免费额度使用情况，超出将会产生费用。</li>
      <li>本教程以 Zhipu LLM 为例来介绍问答机器人的搭建，您也可以选择使用其他 LLM 进行搭建，选用其他 LLM 需要更新 .env 文件中的 API_KEY、LLM_BASE_URL 和 LLM_MODEL。</li></ul>
    </main>

    ![1](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/zhipu-dashboard.png)
    ![2](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/zhipu-api-key.png)

2. 克隆代码仓库。

    ```shell
    git clone https://github.com/oceanbase-devhub/ai-workshop-2024.git
    cd ai-workshop-2024 
    ```

3. 安装依赖。

    ```shell
    poetry install
    ```

4. 设置环境变量。

    ```shell
    cp .env.example .env
    # 更新 .env 文件中的数据库信息
    vi .env
    ```

    更新 .env 中内容。

    ```shell
    API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxx ## 此处为上述 Zhipu LLM 平台中获取的 API 密钥
    LLM_BASE_URL="https://open.bigmodel.cn/api/paas/v4/"  ## 如果选用非 Zhipu 的其他 LLM，则需要更新此字段
    LLM_MODEL="glm-4-flash"  ## 如果选用非 Zhipu 的其他 LLM，则需要更新此字段

    HF_ENDPOINT=https://hf-mirror.com
    BGE_MODEL_PATH=BAAI/bge-m3

    DB_HOST="127.0.0.1"     ## 设置对应租户的 IP
    DB_PORT="2881"   ## 设置对应租户的端口
    DB_USER="root@mysql_tenant"  ## 设置对应的租户及用户名
    DB_NAME="test"      ## 设置对应的数据库名
    DB_PASSWORD=""      ## 设置对应的租户用户的密码
    ```

5. 准备 BGE-M3 模型。

    ```shell
    poetry run python utils/prepare_bgem3.py
    ```

    返回如下结果，说明模型加载成功。

    ```shell
    # ===================================
    # BGEM3FlagModel loaded successfully.
    # ===================================
    ```

6. 准备文档语料。

    <main id="notice" type='explain'>
      <h4>说明</h4>
      <p>此过程需要将 OceanBase 开源的文档转换为向量并且储存在 OceanBase 数据库中，需要花费较长时间。</p>
    </main>

   1. 克隆文档仓库。

        ```shell
        cd doc_repos
        git clone --single-branch --branch V4.3.3 https://github.com/oceanbase/oceanbase-doc.git
        cd ..
        ```

   2. 将标题转换为标准 Markdown 格式。

        ```shell
        poetry run python convert_headings.py \
          doc_repos/oceanbase-doc/zh-CN 
        ```

   3. 将文档文本嵌入为向量。

        ```shell
        poetry run python embed_docs.py --doc_base doc_repos/oceanbase-doc/zh-CN
        ```

7. 启动 UI 聊天界面。

    ```shell
    poetry run streamlit run --server.runOnSave false chat_ui.py
    ```

    返回结果如下：

    ```shell
    Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.

        You can now view your Streamlit app in your browser.

        Local URL: http://localhost:8501
        Network URL: http://xxx.xxx.xxx.xxx:8501
        External URL: http://xxx.xxx.xxx.xxx:8501
    ```

## 应用展示

根据实际情况，通过上述启动 UI 聊天界面中的地址，在浏览器内打开，即可向助手提问。

由于本应用基于 OceanBase 文档语料构建，请就 OceanBase 相关问题向您的助手提问。

![3](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/cloud/tutorial/rag_pic.png)
